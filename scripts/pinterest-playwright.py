#!/usr/bin/env python3
"""
Pinterest Scraper avec Playwright - Navigation humaine
Simule un vrai utilisateur pour contourner toutes les protections
"""

import asyncio
import random
import time
import sys
import json
import re
from pathlib import Path
import requests
from urllib.parse import quote_plus

async def scrape_pinterest_with_playwright(query, count=3):
    """Scrape Pinterest avec vraie navigation browser"""
    
    try:
        from playwright.async_api import async_playwright
    except ImportError:
        print("âŒ Playwright non installÃ©. Installation...")
        import subprocess
        subprocess.run([sys.executable, "-m", "pip", "install", "playwright"], check=True)
        subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], check=True)
        from playwright.async_api import async_playwright
    
    async with async_playwright() as p:
        # Lancer Chrome en mode headless optimisÃ©
        browser = await p.chromium.launch(
            headless=True,  # Mode invisible
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-features=VizDisplayCompositor',
                '--disable-web-security',
                '--disable-features=TranslateUI',
                '--no-first-run',
                '--no-default-browser-check',
                '--disable-gpu',
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-extensions',
                '--disable-plugins',
                '--disable-images',  # Plus rapide
                '--disable-javascript',  # Pas besoin pour le scraping
            ]
        )
        
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )
        
        page = await context.new_page()
        
        # Masquer l'automatisation
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
        """)
        
        print("ğŸŒ Ouverture Pinterest...")
        # Navigation plus rapide avec timeout rÃ©duit
        await page.goto('https://www.pinterest.fr/', wait_until='domcontentloaded', timeout=15000)
        
        # Pause rÃ©duite en mode headless
        await page.wait_for_timeout(random.randint(1000, 2000))
        
        # Scrolling naturel pour charger les ressources
        print("ğŸ“œ Scrolling naturel...")
        for i in range(3):
            await page.mouse.wheel(0, random.randint(200, 500))
            await page.wait_for_timeout(random.randint(800, 1500))
        
        # Navigation vers la recherche
        print(f"ğŸ” Recherche: {query}")
        search_url = f'https://www.pinterest.fr/search/pins/?q={quote_plus(query)}'
        
        await page.goto(search_url, wait_until='domcontentloaded', timeout=15000)
        await page.wait_for_timeout(random.randint(2000, 3000))
        
        # Scrolling pour charger plus d'images
        print("ğŸ“¸ Chargement des images...")
        for i in range(5):
            await page.mouse.wheel(0, random.randint(500, 1000))
            await page.wait_for_timeout(random.randint(1000, 2000))
        
        # Extraction des images
        print("ğŸ¯ Extraction des URLs d'images...")
        
        # Attendre que les images se chargent
        await page.wait_for_selector('img[src*="pinimg.com"]', timeout=10000)
        
        # RÃ©cupÃ©rer toutes les images Pinterest
        image_elements = await page.query_selector_all('img[src*="pinimg.com"]')
        
        image_urls = []
        for img_element in image_elements:
            src = await img_element.get_attribute('src')
            if src and 'pinimg.com' in src:
                # Convertir en URL haute rÃ©solution
                high_res_url = convert_to_high_res(src)
                if high_res_url and high_res_url not in image_urls:
                    image_urls.append(high_res_url)
                    if len(image_urls) >= count:
                        break
        
        print(f"âœ… TrouvÃ© {len(image_urls)} images haute rÃ©solution")
        
        await browser.close()
        return image_urls

def convert_to_high_res(pinterest_url):
    """Convertit une URL Pinterest en version haute rÃ©solution"""
    if not pinterest_url or 'pinimg.com' not in pinterest_url:
        return None
    
    # Pinterest utilise des patterns prÃ©visibles pour les tailles
    # Remplacer par la plus haute rÃ©solution disponible
    url = pinterest_url
    
    # Remplacements pour obtenir la meilleure qualitÃ©
    replacements = [
        ('236x/', 'originals/'),
        ('474x/', 'originals/'),
        ('564x/', 'originals/'),
        ('736x/', 'originals/'),
        ('200x150/', 'originals/'),
        ('/150x150/', '/originals/'),
    ]
    
    for old, new in replacements:
        if old in url:
            url = url.replace(old, new)
            break
    
    return url

def download_image(url, filename):
    """TÃ©lÃ©charge une image avec headers Pinterest"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.pinterest.fr/',
            'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
            'Sec-Fetch-Dest': 'image',
            'Sec-Fetch-Mode': 'no-cors',
            'Sec-Fetch-Site': 'cross-site'
        }
        
        response = requests.get(url, headers=headers, timeout=15, stream=True)
        response.raise_for_status()
        
        # CrÃ©er le dossier si nÃ©cessaire
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
        
        with open(filename, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print(f"âœ… TÃ©lÃ©chargÃ©: {Path(filename).name}")
        return True
        
    except Exception as e:
        print(f"âŒ Ã‰chec tÃ©lÃ©chargement {Path(filename).name}: {e}")
        return False

async def main():
    if len(sys.argv) < 2:
        print("Usage: python3 pinterest-playwright.py 'requÃªte' [nombre]")
        print("Exemple: python3 pinterest-playwright.py 'salon moderne dÃ©co' 3")
        sys.exit(1)
    
    query = sys.argv[1]
    count = int(sys.argv[2]) if len(sys.argv) > 2 else 5  # 5 images minimum
    
    print("ğŸ­ Pinterest Playwright Scraper")
    print(f"ğŸ” RequÃªte: {query}")
    print(f"ğŸ“¸ Images: {count}")
    print("ğŸ”‡ Mode headless - Aucune fenÃªtre ne s'ouvrira")
    print()
    
    # Scraping avec navigation rÃ©elle
    image_urls = await scrape_pinterest_with_playwright(query, count)
    
    if not image_urls:
        print("âŒ Aucune image trouvÃ©e")
        return
    
    print(f"ğŸ¯ {len(image_urls)} images Ã  tÃ©lÃ©charger")
    print()
    
    # TÃ©lÃ©chargement
    output_dir = "site/public/images"
    downloaded = 0
    
    for i, url in enumerate(image_urls):
        timestamp = int(time.time() * 1000) + i
        safe_query = re.sub(r'[^a-z0-9-]', '-', query.lower())
        filename = f"{output_dir}/pinterest-{safe_query}-{timestamp}.jpg"
        
        if download_image(url, filename):
            downloaded += 1
        
        # Pause entre tÃ©lÃ©chargements
        time.sleep(random.uniform(1, 3))
    
    print()
    print(f"ğŸ‰ Scraping terminÃ©: {downloaded}/{len(image_urls)} images tÃ©lÃ©chargÃ©es")
    print(f"ğŸ“ Dossier: {output_dir}")

if __name__ == "__main__":
    asyncio.run(main())